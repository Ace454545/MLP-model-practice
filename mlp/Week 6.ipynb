{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7905698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Create a new dataset with first 10000 images for training and next 2000 images for testing\n",
    "X_train, y_train = X[:10000], y[:10000]\n",
    "X_test, y_test = X[10000:12000], y[10000:12000]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a3b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(863, 784) (1032, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[y_train=='5'].shape,X_train[y_train == '3'].shape)\n",
    "X_train = np.concatenate((X_train[y_train == '5'], X_train[y_train == '3']))\n",
    "X_test = np.concatenate((X_test[y_test == '5'], X_test[y_test == '3']))\n",
    "\n",
    "# Collect the respective labels\n",
    "y_train = np.concatenate((y_train[y_train == '5'], y_train[y_train == '3']))\n",
    "y_test = np.concatenate((y_test[y_test == '5'], y_test[y_test == '3']))\n",
    "\n",
    "y_train = np.where(y_train == '5', 1, -1)\n",
    "y_test = np.where(y_test == '5', 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d589d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083d32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 784) (381, 784) (1895,) (381,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71379f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import hinge_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict,GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf6a9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(random_state=42, eta0=1, max_iter=100, shuffle=True, fit_intercept=True, penalty=None)\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88addcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190   6]\n",
      " [ 12 173]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba1c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 173 6 12\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = cm\n",
    "tn = cf_matrix[0,0]\n",
    "fn = cf_matrix[1,0]\n",
    "fp = cf_matrix[0,1]\n",
    "tp = cf_matrix[1,1]\n",
    "print(tn,tp,fp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "510c4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  0.07027027027027027\n",
      "Accuracy:  0.5485564304461942\n"
     ]
    }
   ],
   "source": [
    "#shuffle false\n",
    "precision = tp/(tp+fp)\n",
    "print('Precision: ',precision)\n",
    "recall = tp/(tp+fn)\n",
    "print('Recall: ',recall)\n",
    "accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
    "print('Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30ff241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9664804469273743\n",
      "Recall:  0.9351351351351351\n",
      "Accuracy:  0.952755905511811\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp)\n",
    "print('Precision: ',precision)\n",
    "recall = tp/(tp+fn)\n",
    "print('Recall: ',recall)\n",
    "accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
    "print('Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
